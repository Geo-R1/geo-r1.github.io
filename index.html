<!DOCTYPE html>
<html lang="en" class="scroll-smooth">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Paper Title | Your Name</title>
    
    <!-- Tailwind CSS for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- Google Fonts: Inter for a clean, modern look -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- Font Awesome for icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" xintegrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin="anonymous" referrerpolicy="no-referrer" />

    <style>
        /* Custom styles */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f8fafc; /* Lighter gray background */
        }

        /* Styling for the hero section gradient */
        .hero-gradient {
            background: linear-gradient(135deg, rgba(236, 243, 255, 0.7), rgba(224, 238, 255, 0.3));
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
        }

        /* Animation for sections */
        .fade-in-up {
            opacity: 0;
            transform: translateY(20px);
            transition: opacity 0.6s ease-out, transform 0.6s ease-out;
        }

        /* Styling for video container */
        .video-container {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            height: 0;
            overflow: hidden;
            max-width: 100%;
            background: #000;
            border-radius: 0.5rem;
        }

        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
    </style>
</head>

<body class="text-gray-800 antialiased">

    <!-- Header Navigation -->
    <header class="bg-white/80 backdrop-blur-md sticky top-0 z-50 border-b border-gray-200">
        <div class="container mx-auto px-6 py-4 flex justify-between items-center">
            <h1 class="text-xl font-bold text-gray-900">Your Name</h1>
            <nav class="hidden md:flex space-x-8">
                <a href="#abstract" class="text-gray-600 hover:text-blue-600 transition duration-300">Abstract</a>
                <a href="#dataset" class="text-gray-600 hover:text-blue-600 transition duration-300">Dataset</a>
                <a href="#reu" class="text-gray-600 hover:text-blue-600 transition duration-300">REU</a>
                <a href="#reward" class="text-gray-600 hover:text-blue-600 transition duration-300">Reward</a>
                <a href="#results" class="text-gray-600 hover:text-blue-600 transition duration-300">Results</a>
                <a href="#contact" class="text-gray-600 hover:text-blue-600 transition duration-300">Contact</a>
            </nav>
            <button id="mobile-menu-button" class="md:hidden text-gray-700">
                <i class="fas fa-bars fa-lg"></i>
            </button>
        </div>
        <!-- Mobile Menu -->
        <div id="mobile-menu" class="hidden md:hidden px-6 pb-4">
            <a href="#abstract" class="block py-2 text-gray-600 hover:text-blue-600">Abstract</a>
            <a href="#dataset" class="block py-2 text-gray-600 hover:text-blue-600">Dataset</a>
            <a href="#reu" class="block py-2 text-gray-600 hover:text-blue-600">reu</a>
            <a href="#reward" class="block py-2 text-gray-600 hover:text-blue-600">Reward</a>
            <a href="#results" class="block py-2 text-gray-600 hover:text-blue-600">Results</a>
            <a href="#contact" class="block py-2 text-gray-600 hover:text-blue-600">Contact</a>
        </div>
    </header>

    <main>
        <!-- Hero Section -->
        <section class="py-20 md:py-32 hero-gradient">
            <div class="container mx-auto px-6 text-center">
                <p class="text-lg font-semibold text-blue-600 mb-4">Conference Name</p>
                <h2 class="text-4xl md:text-6xl font-extrabold text-gray-900 mb-6 leading-tight">
                    Geo-R1: Improving Few-Shot Geospatial Referring Expression Understanding with Reinforcement Fine-Tuning
                </h2>
                <p class="max-w-3xl mx-auto text-lg text-gray-600 mb-8">
                    Reasoning Models and Few-shot Benchmarks for Remote Sensing Referring Expression Understanding Tasks.
                </p>
                
                <!-- Authors -->
                <div class="flex justify-center flex-wrap gap-x-8 gap-y-4 mb-10 text-lg">
                    <span><strong>AnonymousÂ¹</strong></span>
                    <span>AnonymousÂ²</span>
                    <span>AnonymousÂ¹</span>
                    <span>AnonymousÂ²</span>
                </div>
                <div class="flex justify-center flex-wrap gap-x-6 gap-y-2 text-md text-gray-500">
                    <span>Â¹Anonymous Institution</span>
                    <span>Â²Anonymous Institution</span>
                </div>

                <!-- Action Buttons -->
                <div class="mt-12 flex flex-wrap justify-center gap-4">
                    <a href="path/to/your/paper.pdf" class="inline-block bg-blue-600 text-white font-semibold py-3 px-8 rounded-lg shadow-md hover:bg-blue-700 transition-transform transform hover:scale-105 duration-300">
                        <i class="fas fa-file-pdf mr-2"></i> Paper PDF
                    </a>
                    <a href="https://github.com/Geo-R1/geo-r1" target="_blank" class="inline-block bg-gray-800 text-white font-semibold py-3 px-8 rounded-lg shadow-md hover:bg-gray-900 transition-transform transform hover:scale-105 duration-300">
                        <i class="fab fa-github mr-2"></i> View Code
                    </a>
                    <a href="https://huggingface.co/Geo-R1" target="_blank" class="inline-block bg-white text-gray-800 font-semibold py-3 px-8 rounded-lg shadow-md hover:bg-gray-100 border border-gray-200 transition-transform transform hover:scale-105 duration-300">
                        <span class="mr-2">ðŸ¤—</span> Hugging Face
                    </a>
                </div>
            </div>
        </section>

        <!-- Teaser Image Section -->
        <section id="teaser" class="py-20 bg-white">
            <div class="container mx-auto px-6">
                <div class="max-w-5xl mx-auto">
                    <img src="fig_1.png" alt="Teaser figure for the paper" class="rounded-lg shadow-2xl w-full">
                    <p class="text-center mt-4 text-gray-500">
                        Geo-R1 method overview. Geo-R1 is trained on a few labeled samples with reinforcement learning (e.g., GRPO) and can identify target objects (bounding boxes or masks) from an input image and text query while providing the reasoning process.
                    </p>
                </div>
            </div>
        </section>

        <!-- Abstract Section -->
        <section id="abstract" class="py-20">
            <div class="container mx-auto px-6">
                <div class="max-w-3xl mx-auto">
                    <h3 class="text-3xl font-bold text-center mb-8">Abstract</h3>
                    <p class="text-lg leading-relaxed text-gray-700 bg-white p-8 rounded-lg shadow-lg border border-gray-200">
                        Referring expression understanding in remote sensing poses unique challenges, as it requires reasoning over complex objectâ€“context relationships. While supervised fine-tuning (SFT) on multimodal large language models achieves strong performance with massive labeled datasets, they struggle in data-scarce scenarios, leading to poor generalization. To address this limitation, we propose Geo-R1, a reasoning-centric reinforcement fine-tuning (RFT) paradigm for few-shot geospatial referring. Geo-R1 enforces the model to first generate explicit, interpretable reasoning chains that decompose referring expressions, and then leverage these rationales to localize target objects. This ``reason first, then act" process enables the model to make more effective use of limited annotations, enhances generalization, and provides interpretability. We validate Geo-R1 on three carefully designed few-shot geospatial referring benchmarks, where our model consistently and substantially outperforms SFT baselines. It also demonstrates strong cross-dataset generalization, highlighting its robustness.
                    </p>
                </div>
            </div>
        </section>
        
        <!-- Referring Expression Understanding Section -->
        <section id="reu" class="py-20 bg-white">
            <div class="container mx-auto px-6">
                 <h3 class="text-3xl font-bold text-center mb-12">Referring Expression Understanding</h3>
                <div class="max-w-5xl mx-auto">
                    <img src="https://placehold.co/1200x600/e2e8f0/64748b?text=REU+Framework+Figure" alt="Figure for Referring Expression Understanding" class="rounded-lg shadow-xl w-full">
                    <p class="text-center mt-4 text-gray-500">
                        Fig 2: An overview of Referring Expression Understanding task
                    </p>
                    <p class="text-lg leading-relaxed text-gray-700">
                        Tasks such as REC, RES, Generalized REC (GREC), Generalized RES (GRES), Visual Grounding (VG), Open-Vocabulary Detection (OVD), and Open-Vocabulary Segmentation (OVS) can all be seen as specialized forms of REU, each with a different emphasis.
                    </p>
                </div>
            </div>
        </section>

        <!-- Dataset Section -->
        <section id="dataset" class="py-20">
            <div class="container mx-auto px-6">
                <h3 class="text-3xl font-bold text-center mb-12">Dataset</h3>
                <div class="max-w-5xl mx-auto">
                    <img src="fig_dataset.png" alt="Dataset statistics figure" class="rounded-lg shadow-xl w-full mb-6">
                    <p class="text-lg leading-relaxed text-gray-700">
                        We do not partition the dataset into base and novel classes. Instead, we treat all classes as novel and provide only a few labeled examples per class. We construct instruction-following few-shot datasets for the FS-GREC and FS-GRES tasks by deriving them from the training sets of three widely used remote sensing benchmarks: VRSBench, NWPU VHR-10, and EarthReason. Configurations and statistics are summarized in the table above. For the OVD task, we select four classes on which the baseline model (Qwen2.5-VL-3B) demonstrated decent performance. We select all categories from the training set for other tasks. The low-shot dataset is a subset of the high-shot dataset. To evaluate cross-dataset generalization, we further evaluate zero-shot performance on DIOR-RSVG and RRSIS-D datasets.
                    </p>
                </div>
            </div>
        </section>
        
        <!-- Method Section -->
        <section id="reward" class="py-20 bg-white">
            <div class="container mx-auto px-6">
                <h3 class="text-3xl font-bold text-center mb-12">Reward</h3>
                <div class="max-w-5xl mx-auto grid md:grid-cols-2 gap-12 items-center">
                    <div class="order-2 md:order-1">
                        <h4 class="text-2xl font-semibold mb-4">Reward Design</h4>
                        <p class="text-gray-700 leading-loose">
                          Following DeepSeek-R1, the reward function of Geo-R1 includes a task-agnostic format reward and a task-specific metrics reward. 
                        </p>
                    </div>
                    <div class="order-1 md:order-2">
                        <img src="fig_reward.png" alt="Diagram of the model architecture" class="rounded-lg shadow-xl w-full">
                         <p class="text-center mt-4 text-gray-500">
                           Fig 2: Reward Design
                        </p>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- Results Section -->
        <section id="results" class="py-20">
            <div class="container mx-auto px-6">
                <h3 class="text-3xl font-bold text-center mb-12">Experimental Results</h3>
                <div class="max-w-6xl mx-auto">
                     <p class="text-center text-lg text-gray-600 max-w-3xl mx-auto mb-12">
                        We evaluated our method on several public datasets and compared it with state-of-the-art approaches. The data for the low-shot setting is a subset of the data for the many-shot setting.
                    </p>
                    <!-- Qualitative Results -->
                    <h4 class="text-2xl font-semibold mb-6 text-center">Qualitative Results</h4>
                    <div class="space-y-16 mb-12">
                        <!-- First Large Image -->
                        <div class="max-w-5xl mx-auto">
                           <img src="fig_sample1.png" alt="First qualitative result" class="rounded-lg shadow-xl w-full border border-gray-200">
                           <p class="text-center mt-4 text-gray-500">
                              Sample Fig 1: Demo for GRES task.
                           </p>
                        </div>
                        <!-- Second Large Image -->
                        <div class="max-w-5xl mx-auto">
                           <img src="fig_sample2.png" alt="Second qualitative result" class="rounded-lg shadow-xl w-full border border-gray-200">
                           <p class="text-center mt-4 text-gray-500">
                              Sample Fig 2: Demo for GREC task.
                           </p>
                        </div>
                    </div>

                    <!-- Quantitative Results -->
                    <h4 class="text-2xl font-semibold mb-6 text-center">Quantitative Results</h4>
                    <div class="max-w-5xl mx-auto">
                        <img src="fig_table2.png" alt="Quantitative results table" class="rounded-lg shadow-xl w-full">
                        <p class="text-center mt-4 text-gray-500">
                          Table 2: Comparison with state-of-the-art methods on VRSBench Dataset.
                       </p>
                   </div>
                </div>
            </div>
        </section>
        
        <!-- Citation Section -->
        <section id="citation" class="py-20">
            <div class="container mx-auto px-6">
                 <h3 class="text-3xl font-bold text-center mb-8">Citation</h3>
                <div class="max-w-3xl mx-auto bg-white p-8 rounded-lg shadow-lg border border-gray-200">
                    <pre class="bg-gray-100 p-6 rounded-md text-gray-700 overflow-x-auto"><code>@inproceedings{YourLastName2025AwesomeTitle,
      title={Your Awesome Paper Title Here},
      author={Your Name and Collaborator Name and Supervisor Name},
      booktitle={Conference Name},
      year={2025}
}</code></pre>
                    <button id="copy-btn" class="mt-4 bg-gray-200 text-gray-800 font-semibold py-2 px-6 rounded-lg hover:bg-gray-300 transition duration-300 w-full md:w-auto">
                        <i class="fas fa-copy mr-2"></i> Copy BibTeX
                    </button>
                    <span id="copy-success" class="ml-4 text-green-600 hidden">Copied!</span>
                </div>
            </div>
        </section>

    </main>
    
    <!-- Footer -->
    <footer id="contact" class="bg-gray-800 text-white py-16">
        <div class="container mx-auto px-6 text-center">
            <h3 class="text-3xl font-bold mb-8">Contact Us</h3>
            <p class="text-gray-400 mb-8 max-w-xl mx-auto">
                If you have any questions or suggestions about our work, please feel free to contact us.
            </p>
            <div class="flex justify-center items-center space-x-8 text-2xl">
                <a href="mailto:your.email@example.com" class="text-gray-400 hover:text-white transition duration-300"><i class="fas fa-envelope"></i></a>
                <a href="https://github.com/your-username" target="_blank" class="text-gray-400 hover:text-white transition duration-300"><i class="fab fa-github"></i></a>
                <a href="https://scholar.google.com/citations?user=your_scholar_id" target="_blank" class="text-gray-400 hover:text-white transition duration-300"><i class="fas fa-graduation-cap"></i></a>
            </div>
            <p class="mt-10 text-gray-500 text-sm">&copy; 2025 Your Name. All Rights Reserved.</p>
        </div>
    </footer>

    <script>
        // --- Mobile Menu Toggle ---
        const mobileMenuButton = document.getElementById('mobile-menu-button');
        const mobileMenu = document.getElementById('mobile-menu');

        mobileMenuButton.addEventListener('click', () => {
            mobileMenu.classList.toggle('hidden');
        });

        // --- Smooth Scrolling for all anchor links ---
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
                // Close mobile menu on click
                if (!mobileMenu.classList.contains('hidden')) {
                    mobileMenu.classList.add('hidden');
                }
            });
        });

        // --- BibTeX Citation Copy ---
        const copyBtn = document.getElementById('copy-btn');
        const copySuccess = document.getElementById('copy-success');
        
        copyBtn.addEventListener('click', () => {
            const bibtexCode = document.querySelector('pre code').innerText;
            navigator.clipboard.writeText(bibtexCode).then(() => {
                copySuccess.classList.remove('hidden');
                setTimeout(() => {
                    copySuccess.classList.add('hidden');
                }, 2000);
            });
        });

        // --- Section Fade-in Animation on Scroll ---
        const sections = document.querySelectorAll('section');
        const observer = new IntersectionObserver(entries => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = 1;
                    entry.target.style.transform = 'translateY(0)';
                    // Optional: unobserve after animating to save resources
                    // observer.unobserve(entry.target);
                }
            });
        }, {
            threshold: 0.1
        });
        
        sections.forEach(section => {
            section.classList.add('fade-in-up');
            observer.observe(section);
        });
    </script>
</body>

</html>

